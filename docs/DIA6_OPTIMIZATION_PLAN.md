# DIA 6 - EXTENDED SIMD OPTIMIZATION PLAN

**Data**: 10 de Janeiro de 2026  
**Objetivo**: Expandir otimiza√ß√µes SIMD para opera√ß√µes adicionais

---

## üéØ Opera√ß√µes Candidatas para Otimiza√ß√£o

### Prioridade ALTA (Impacto significativo)

1. **divide()** - Elemento-a-elemento
   - Instru√ß√µes: `_mm256_div_ps()`
   - Speedup esperado: ~7-8x (similar a add/mul)
   - Uso: Opera√ß√µes de normaliza√ß√£o
   - Status: ‚è≥ TODO

2. **scalar_multiply()** - Broadcast + multiplica√ß√£o
   - Instru√ß√µes: `_mm256_set1_ps()` + `_mm256_mul_ps()`
   - Speedup esperado: ~7-8x
   - Uso: Muito comum em processamento
   - Status: ‚è≥ TODO

3. **scalar_divide()** - Broadcast + divis√£o
   - Instru√ß√µes: `_mm256_set1_ps()` + `_mm256_div_ps()`
   - Speedup esperado: ~7-8x
   - Uso: Normaliza√ß√£o
   - Status: ‚è≥ TODO

4. **scalar_add()** e **scalar_subtract()**
   - Instru√ß√µes: `_mm256_set1_ps()` + `_mm256_add_ps()` / `_mm256_sub_ps()`
   - Speedup esperado: ~7-8x
   - Status: ‚è≥ TODO

### Prioridade M√âDIA (Impacto moderado)

5. **leaky_relu()** - Com par√¢metro alpha
   - Instru√ß√µes: `_mm256_cmp_ps()` + `_mm256_blendv_ps()`
   - Speedup esperado: ~3-5x
   - Status: ‚è≥ TODO

6. **pow()** - Exponencia√ß√£o
   - Desafio: N√£o h√° `_mm256_pow_ps()` nativa
   - Alternativa: Usar exponencia√ß√£o com LUT (Lookup Table)
   - Speedup esperado: ~2-4x
   - Status: ‚è≥ RESEARCH NEEDED

7. **exp()** - Exponencial
   - Instru√ß√µes: Approximate exp com polin√¥mios ou LUT
   - Speedup esperado: ~3-5x
   - Status: ‚è≥ TODO

8. **log()** - Logaritmo
   - Instru√ß√µes: Approximate log com polin√¥mios
   - Speedup esperado: ~3-5x
   - Status: ‚è≥ TODO

### Prioridade BAIXA (Uso raro)

9. **clip()** - Clamp para outro tensor
   - Instru√ß√µes: `_mm256_max_ps()` + `_mm256_min_ps()`
   - Speedup esperado: ~3-4x
   - Status: ‚è≥ TODO (se houver tempo)

10. **std()** - Desvio padr√£o
    - Desafio: Opera√ß√£o de redu√ß√£o complexa
    - Pode melhorar com SIMD para quadrados
    - Status: ‚è≥ RESEARCH NEEDED

---

## üìã Implementa√ß√£o por Fase

### Fase 1: Opera√ß√µes Escalares (F√ÅCIL - Alta Prioridade)
```cpp
// Padr√£o para estas opera√ß√µes:
// 1. Criar vetor com scalar: _mm256_set1_ps(scalar)
// 2. Aplicar opera√ß√£o em paralelo
// 3. Armazenar resultado
// 4. Processar tail loop manualmente
```

**Fun√ß√µes**: scalar_add, scalar_subtract, scalar_multiply, scalar_divide

### Fase 2: Elemento-a-Elemento (M√âDIO)
```cpp
// Padr√£o:
// 1. Carregar dois vetores: _mm256_loadu_ps()
// 2. Aplicar opera√ß√£o: _mm256_div_ps(), etc
// 3. Armazenar: _mm256_storeu_ps()
// 4. Loop tail
```

**Fun√ß√µes**: divide

### Fase 3: Fun√ß√µes Matem√°ticas (DIF√çCIL)
```cpp
// Requer aproxima√ß√£o polinomial ou LUT
// Mais complexo, mas grande impacto em ML
```

**Fun√ß√µes**: exp, log, pow, leaky_relu

---

## üß™ Testes Planejados

Para cada fun√ß√£o otimizada:
1. Correctness test (comparar com vers√£o scalar)
2. Performance benchmark (speedup measurement)
3. Edge case validation (NaN, Inf, denormalized)

---

## üìä Objetivo Final

```
Opera√ß√µes Antes do DIA 6:
‚îú‚îÄ add/mul/sub:         7.98x ‚úÖ
‚îú‚îÄ relu/sigmoid/tanh:   3.61x ‚úÖ
‚îú‚îÄ abs/sqrt:            3-7x  ‚úÖ
‚îú‚îÄ min/max/sum:         3-4x  ‚úÖ
‚îî‚îÄ scalar/divide:       1.0x  ‚è≥

Opera√ß√µes Depois do DIA 6 (ALVO):
‚îú‚îÄ add/mul/sub:         7.98x ‚úÖ
‚îú‚îÄ relu/sigmoid/tanh:   3.61x ‚úÖ
‚îú‚îÄ abs/sqrt:            3-7x  ‚úÖ
‚îú‚îÄ min/max/sum:         3-4x  ‚úÖ
‚îú‚îÄ scalar/divide:       7-8x  ‚è≥ ‚Üí NEW
‚îú‚îÄ leaky_relu:          3-5x  ‚è≥ ‚Üí NEW
‚îî‚îÄ exp/log/pow:         3-5x  ‚è≥ ‚Üí NEW
```

---

## üöÄ Pr√≥ximos Passos

1. Implementar Fase 1 (scalar operations)
2. Criar benchmark suite
3. Implementar Fase 2 (divide)
4. Testar e validar
5. Considerar Fase 3 (se houver tempo)
6. Documentar resultados finais
