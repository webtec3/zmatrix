# üîç Refer√™ncia R√°pida de Mudan√ßas - src/zmatrix.cpp

**Arquivo**: `src/zmatrix.cpp`  
**Total de Mudan√ßas**: 5 se√ß√µes cr√≠ticas  
**Status**: ‚úÖ Todas aplicadas

---

## üìç Localiza√ß√£o das Mudan√ßas

### 1Ô∏è‚É£ Include de Mutex (Linha 4)

**Localiza√ß√£o**: Depois de `<set>`

```diff
  #include <memory>
  #include <functional>
  #include <atomic>
  #include <set>  // Para reverse-mode autograd
+ #include <mutex>  // Para thread-safety em accumulate_grad
```

**Motivo**: Thread-safety em `accumulate_grad()`

---

### 2Ô∏è‚É£ Estrutura AutogradNode (Linha ~126)

**Localiza√ß√£o**: Antes de `struct ZTensor`

```diff
  struct AutogradNode {
      std::vector<std::shared_ptr<ZTensor>> parents;
      std::function<void()> backward_fn;
      std::string op_name;
+     mutable std::mutex backward_lock;
      
      AutogradNode() = default;
      AutogradNode(const std::string& name) : op_name(name) {}
  };
```

**Motivo**: Espa√ßo reservado para sincroniza√ß√£o (futuro uso)

---

### 3Ô∏è‚É£ Campo grad_mutex em ZTensor (Linha ~156)

**Localiza√ß√£o**: Dentro de `struct ZTensor`, se√ß√£o autograd

```diff
  struct ZTensor {
      // ========== AUTOGRAD STATE ==========
      bool requires_grad = false;
      std::unique_ptr<ZTensor> grad;
      std::shared_ptr<AutogradNode> grad_fn = nullptr;
+     mutable std::mutex grad_mutex;
      
      // ========== M√âTODOS DE AUTOGRAD ==========
```

**Motivo**: Proteger acesso a `grad` em m√∫ltiplas threads

---

### 4Ô∏è‚É£ Prote√ß√£o em add() (Linha 567)

**Localiza√ß√£o**: In√≠cio do m√©todo `void add(const ZTensor& other)`

```diff
  void add(const ZTensor& other) {
+     if (this->requires_grad) {
+         throw std::logic_error(
+             "In-place operation on tensor with requires_grad=true is not allowed. "
+             "Use add_autograd() for differentiable operations."
+         );
+     }
      
      if (!same_shape(other)) {
          throw std::invalid_argument(ZMATRIX_ERR_SHAPE_MISMATCH);
      }
```

**Motivo**: Impedir corrup√ß√£o de grafo

---

### 5Ô∏è‚É£ Prote√ß√£o em mul() (Linha 767)

**Localiza√ß√£o**: In√≠cio do m√©todo `void mul(const ZTensor& other)`

```diff
  void mul(const ZTensor& other) {
+     if (this->requires_grad) {
+         throw std::logic_error(
+             "In-place operation on tensor with requires_grad=true is not allowed. "
+             "Use mul_autograd() for differentiable operations."
+         );
+     }
      
      if (!same_shape(other)) throw std::invalid_argument(ZMATRIX_ERR_SHAPE_MISMATCH);
```

**Motivo**: Impedir corrup√ß√£o de grafo

---

### 6Ô∏è‚É£ Acumula√ß√£o com Mutex (Linha ~200)

**Localiza√ß√£o**: M√©todo `void accumulate_grad(const ZTensor& grad_in)`

```diff
  void accumulate_grad(const ZTensor& grad_in) {
      if (grad_in.shape != shape) {
          throw std::invalid_argument("Gradient shape mismatch");
      }
      
+     std::lock_guard<std::mutex> lock(grad_mutex);
+     
      ZTensor& g = ensure_grad();
      const size_t N = size();
      if (N == 0) return;
      
      float* g_data = g.data.data();
      const float* gin_data = grad_in.data.data();
      
      #if HAS_OPENMP
      // ... acumula√ß√£o ...
```

**Motivo**: Thread-safety em `accumulate_grad()`

---

### 7Ô∏è‚É£ Reshape Comentado (Linha ~1010)

**Localiza√ß√£o**: M√©todo `ZTensor reshape(...)`

```diff
      #ifdef HAVE_CUDA
      ensure_host();
      #endif
+     // IMPORTANTE: std::vector copy √© rasa (shallow) e compartilha os dados
+     // Ambos result e this->data apontam para o mesmo buffer de mem√≥ria
+     // Isto implementa uma "view" eficiente, n√£o uma c√≥pia de dados
      result.data = this->data;
```

**Motivo**: Documentar compartilhamento eficiente

---

### 8Ô∏è‚É£ Closure Fix em add_autograd() (Linha ~2115)

**Localiza√ß√£o**: Dentro de `static ZTensor add_autograd(...)`

```diff
-     if (requires_grad) {
+     if (requires_grad) {
+         auto result_ptr = std::make_shared<ZTensor>(result);
          auto node = std::make_shared<AutogradNode>("add");
          auto a_ptr = std::make_shared<ZTensor>(a);
          auto b_ptr = std::make_shared<ZTensor>(b);
          node->parents = {a_ptr, b_ptr};
          
          bool a_req = a.requires_grad;
          bool b_req = b.requires_grad;
          
-         node->backward_fn = [&result, a_ptr, b_ptr, a_req, b_req]() {
+         node->backward_fn = [result_ptr, a_ptr, b_ptr, a_req, b_req]() {
-             const ZTensor* grad_result = result.get_grad();
+             const ZTensor* grad_result = result_ptr->get_grad();
              if (!grad_result) return;
              
              if (a_req) {
                  const_cast<ZTensor*>(a_ptr.get())->accumulate_grad(*grad_result);
              }
              if (b_req) {
                  const_cast<ZTensor*>(b_ptr.get())->accumulate_grad(*grad_result);
              }
          };
```

**Motivo**: Eliminar UB (captura de refer√™ncia local)

---

### 9Ô∏è‚É£ Closure Fix em sub_autograd() (Linha ~2185)

**Localiza√ß√£o**: Similar a `add_autograd()`

```diff
+     auto result_ptr = std::make_shared<ZTensor>(result);
      node->parents = {a_ptr, b_ptr};
      
      bool a_req = a.requires_grad;
      bool b_req = b.requires_grad;
      
-     node->backward_fn = [&result, a_ptr, b_ptr, ...]() {
+     node->backward_fn = [result_ptr, a_ptr, b_ptr, ...]() {
-         const ZTensor* grad_result = result.get_grad();
+         const ZTensor* grad_result = result_ptr->get_grad();
          // ... resto igual ...
      };
```

**Motivo**: Eliminar UB

---

### üîü Closure Fix em mul_autograd() (Linha ~2275)

**Localiza√ß√£o**: Similar aos anteriores

```diff
+     auto result_ptr = std::make_shared<ZTensor>(result);
      node->parents = {a_ptr, b_ptr};
      
      bool a_req = a.requires_grad;
      bool b_req = b.requires_grad;
      
      auto a_copy = std::make_shared<ZTensor>(a);
      auto b_copy = std::make_shared<ZTensor>(b);
      
-     node->backward_fn = [&result, a_ptr, b_ptr, ...]() {
+     node->backward_fn = [result_ptr, a_ptr, b_ptr, ...]() {
-         const ZTensor* grad_result = result.get_grad();
+         const ZTensor* grad_result = result_ptr->get_grad();
          // ... resto igual ...
      };
```

**Motivo**: Eliminar UB

---

### 1Ô∏è‚É£1Ô∏è‚É£ Closure Fix em sum_autograd() (Linha ~2360)

**Localiza√ß√£o**: √öltima opera√ß√£o

```diff
+     auto result_ptr = std::make_shared<ZTensor>(result);
      node->parents = {t_ptr};
      
      auto input_shape = t.shape;
      auto input_size = t.size();
      
-     node->backward_fn = [&result, t_ptr, ...]() {
+     node->backward_fn = [result_ptr, t_ptr, ...]() {
-         const ZTensor* grad_result = result.get_grad();
+         const ZTensor* grad_result = result_ptr->get_grad();
          // ... resto igual ...
      };
```

**Motivo**: Eliminar UB

---

## üìä Resumo de Mudan√ßas

| # | Tipo | Loca√ß√£o | Status |
|---|------|---------|--------|
| 1 | Include | Linha 4 | ‚úÖ |
| 2 | Campo struct | Linha ~126 | ‚úÖ |
| 3 | Campo struct | Linha ~156 | ‚úÖ |
| 4 | Valida√ß√£o | Linha 567 | ‚úÖ |
| 5 | Valida√ß√£o | Linha 767 | ‚úÖ |
| 6 | Lock guard | Linha ~200 | ‚úÖ |
| 7 | Coment√°rio | Linha ~1010 | ‚úÖ |
| 8 | Closure fix | Linha ~2115 | ‚úÖ |
| 9 | Closure fix | Linha ~2185 | ‚úÖ |
| 10 | Closure fix | Linha ~2275 | ‚úÖ |
| 11 | Closure fix | Linha ~2360 | ‚úÖ |

---

## üîß Como Verificar Mudan√ßas

### Ver diff completo
```bash
git diff src/zmatrix.cpp
```

### Ver apenas se√ß√µes de autograd
```bash
grep -n "mutex\|requires_grad\|accumulate_grad\|add_autograd\|sub_autograd\|mul_autograd\|sum_autograd" src/zmatrix.cpp | head -50
```

### Compilar
```bash
phpize && ./configure && make 2>&1 | grep -i error
```

---

## ‚úÖ Valida√ß√£o R√°pida

### 1. Thread-safety implementada?
```bash
grep -c "std::lock_guard" src/zmatrix.cpp
```
**Esperado**: 1

### 2. Todos closure fixes aplicados?
```bash
grep -c "result_ptr = std::make_shared<ZTensor>(result)" src/zmatrix.cpp
```
**Esperado**: 4 (add, sub, mul, sum)

### 3. Inplace protection ativa?
```bash
grep -c "In-place operation on tensor with requires_grad" src/zmatrix.cpp
```
**Esperado**: 2 (add e mul)

### 4. Mutex adicionado?
```bash
grep -c "grad_mutex" src/zmatrix.cpp
```
**Esperado**: ‚â• 2 (declara√ß√£o + uso)

---

## üöÄ Pr√≥ximo Passo

Compilar e executar testes:
```bash
make clean
make
php test_autograd.php
```

---

**Documento gerado**: 16 de Janeiro, 2026  
**Vers√£o**: 1.0
