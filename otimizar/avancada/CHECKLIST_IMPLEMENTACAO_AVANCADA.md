# âœ… CHECKLIST DE IMPLEMENTAÃ‡ÃƒO - TÃ©cnicas AvanÃ§adas

## ðŸŽ¯ Objetivo Final
Implementar **Kernel Fusion + Tree Reduction + Auto-Dispatch** em **5-7 dias**

---

## ðŸ“‹ PHASE 1: TREE REDUCTION (Days 1-2)

### Day 1: FunÃ§Ãµes Base em simd/simd_dispatch.h

- [ ] **sum_f32_tree()**
  - [ ] Blocos de 256 elementos (L2 cache friendly)
  - [ ] SIMD horizontal reduction dentro do bloco
  - [ ] AcumulaÃ§Ã£o final sequencial
  - [ ] Teste com 100M elementos
  - [ ] Benchmark vs versÃ£o simples
  
- [ ] **max_f32_tree()**
  - [ ] Mesmo padrÃ£o que sum
  - [ ] Usar `_mm256_max_ps()` para comparaÃ§Ã£o
  - [ ] Teste unitÃ¡rio
  
- [ ] **min_f32_tree()** (bonus se time)
  - [ ] Similar a max

### Day 2: IntegraÃ§Ã£o em zmatrix.cpp

- [ ] **mean_f32_tree()**
  - [ ] Usar sum_f32_tree() + divisÃ£o
  - [ ] Integrar em `ZTensor::mean()`
  - [ ] Testes
  
- [ ] **std_f32_tree()**
  - [ ] Computar mean primeiro
  - [ ] Tree reduction da variance
  - [ ] Sqrt final
  - [ ] Integrar em `ZTensor::std()`
  - [ ] Testes com diferentes tamanhos
  
- [ ] **Benchmarking Completo**
  - [ ] Criar benchmark_tree_reduction.cpp
  - [ ] Comparar: simples vs tree vs GPU (se disponÃ­vel)
  - [ ] Plotar scaling com nÃºmero de threads
  - [ ] Documentar resultados

---

## ðŸ“‹ PHASE 2: KERNEL FUSION (Days 3-4)

### Day 3: OperaÃ§Ãµes Escalares Fused

- [ ] **fused_mul_add_f32()** em SIMD
  - [ ] ImplementaÃ§Ã£o AVX2 com FMA
  - [ ] Fallback scalar
  - [ ] Teste: `a = a * scale + offset`
  
- [ ] **ZTensor::fused_multiply_add(scale, offset)**
  - [ ] Integrar em zmatrix.cpp
  - [ ] OpenMP + SIMD + CUDA (se houver gpu_fused_*)
  - [ ] Testes
  
- [ ] **fused_mul_add_relu_f32()** em SIMD
  - [ ] AVX2: FMA + max com zero
  - [ ] Teste: `a = max(0, a * b + bias)`
  
- [ ] **Teste de Fusion vs NÃ£o-Fusion**
  - [ ] Confirmar ganho 2-3x
  - [ ] Validar resultados numÃ©ricos

### Day 4: OperaÃ§Ãµes Matriciais Fused

- [ ] **fused_add_relu()** para matrizes
  - [ ] Row-wise broadcast do bias
  - [ ] Teste com diferentes tamanhos
  - [ ] ValidaÃ§Ã£o numÃ©rica vs versÃ£o separada
  
- [ ] **GPU Kernels** (cuda/gpu_wrapper.cu)
  - [ ] `gpu_fused_mul_add_relu()`
  - [ ] `gpu_fused_add_relu()`
  - [ ] Teste de correctness vs CPU
  
- [ ] **Benchmarking Fusion**
  - [ ] Criar benchmark_fusion.cpp
  - [ ] Comparar: fused vs non-fused
  - [ ] Tamanhos: 1K, 100K, 10M
  - [ ] CPU vs GPU
  
- [ ] **DocumentaÃ§Ã£o de PadrÃµes**
  - [ ] Quando usar fusion
  - [ ] Exemplos em zmatrix.php

---

## ðŸ“‹ PHASE 3: AUTO-DISPATCH (Days 5)

### Day 5: Sistema AutomÃ¡tico

- [ ] **DispatchMetrics struct** em zmatrix.cpp
  - [ ] `calibrate_simd()`
  - [ ] `calibrate_openmp()`
  - [ ] `calibrate_gpu()`
  - [ ] `compute_thresholds()`
  
- [ ] **AutoDispatcher class**
  - [ ] MÃ©todo `decide(size_t N, string operation)`
  - [ ] Retorna Target enum (GPU, OpenMP, SIMD, Sequential)
  - [ ] MÃ©todos `apply_*` para cada operaÃ§Ã£o
  
- [ ] **MINIT Hook**
  - [ ] Adicionar `DispatchMetrics::instance().calibrate()` em PHP_MINIT_FUNCTION
  - [ ] Print resultado no STDOUT/logs
  
- [ ] **IntegraÃ§Ã£o em MÃ©todos CrÃ­ticos**
  - [ ] `void add()`
  - [ ] `void mul()`
  - [ ] `double sum()`
  - [ ] `float max()`
  - [ ] Testar dispatch correto
  
- [ ] **Testes de Dispatch**
  - [ ] Verificar que GPU Ã© usado para N grande
  - [ ] Verificar que OpenMP Ã© usado para N mÃ©dio
  - [ ] Verificar que SIMD Ã© usado para N pequeno
  - [ ] Disabilitar GPU e verificar fallback

---

## ðŸ§ª TESTING & VALIDATION (Day 6)

### Testes UnitÃ¡rios

- [ ] **Tree Reduction**
  - [ ] sum vs reference (std::accumulate)
  - [ ] mean vs manual calculation
  - [ ] std vs numpy/scipy
  - [ ] max/min correctness
  
- [ ] **Kernel Fusion**
  - [ ] Resultado numÃ©rico vs operaÃ§Ãµes separadas (1e-5 tolerance)
  - [ ] Overflow/underflow cases
  - [ ] Edge cases (N=1, N=0, muito pequeno)
  
- [ ] **Auto-Dispatch**
  - [ ] Threshold selection lÃ³gico
  - [ ] Fallbacks funcionam
  - [ ] Sem crashes ao desabilitar GPU
  
- [ ] **Regression Tests**
  - [ ] Todos os testes antigos ainda passam
  - [ ] Resultados bit-exact (onde aplicÃ¡vel)

### Benchmarks

- [ ] **CPU Benchmarks**
  - [ ] sum/mean/std (10M elementos)
  - [ ] add/mul (100M elementos)
  - [ ] fused operations vs components
  - [ ] Verificar scaling com threads
  
- [ ] **GPU Benchmarks** (se GPU disponÃ­vel)
  - [ ] Mesmas operaÃ§Ãµes
  - [ ] Comparar CPU vs GPU
  - [ ] Verify dispatch decisions
  
- [ ] **End-to-End Benchmark**
  - [ ] Forward pass de rede neural 3-layer
  - [ ] Antes: 45ms/epoch
  - [ ] Depois: <10ms/epoch (4-5x)

---

## ðŸ“– DOCUMENTATION (Day 7)

### CÃ³digo

- [ ] **ComentÃ¡rios em SIMD**
  - [ ] Explicar cada _mm256_ operaÃ§Ã£o
  - [ ] Documentar fallbacks
  
- [ ] **Documentar Novos MÃ©todos**
  - [ ] `fused_mul_add()`
  - [ ] `fused_mul_add_relu()`
  - [ ] `fused_add_relu()`
  
- [ ] **Atualizar README**
  - [ ] Mencionar tÃ©cnicas avanÃ§adas
  - [ ] Performance gains
  - [ ] Hardware requirements

### Markdown Docs

- [ ] **Criar IMPLEMENTACAO_TECNICAS_AVANCADAS.md**
  - [ ] DecisÃµes de design
  - [ ] Trade-offs considerados
  - [ ] Lessons learned
  
- [ ] **Atualizar ANALISE_OTIMIZACOES.md**
  - [ ] Adicionar resultados reais
  - [ ] Benchmarks executados
  - [ ] ComparaÃ§Ã£o antes/depois

---

## ðŸŽ¯ Checkpoints DiÃ¡rios

### Day 1 Checkpoint
```
âœ… sum_f32_tree implementada
âœ… max_f32_tree implementada
âœ… Benchmark mostra 2.5x ganho
âœ… Testes passam
```

### Day 2 Checkpoint
```
âœ… mean(), std() refatorizadas para tree
âœ… Testes unitÃ¡rios passam
âœ… 3.0-3.4x ganho em std/mean confirmado
âœ… Scaling com threads verifies (14x em 16 cores)
```

### Day 3 Checkpoint
```
âœ… fused_mul_add funcionando (CPU + SIMD)
âœ… fused_mul_add_relu implementada
âœ… Resultados bit-exact vs versÃ£o separada
âœ… 2-3x ganho medido
```

### Day 4 Checkpoint
```
âœ… GPU kernels compilam e executam
âœ… Testes de fusion passam
âœ… Auto-dispatch pronto para integraÃ§Ã£o
âœ… DocumentaÃ§Ã£o draft
```

### Day 5 Checkpoint
```
âœ… DispatchMetrics calibra corretamente
âœ… AutoDispatcher::decide() retorna Target correto
âœ… MÃ©todos kritikos integrados com auto-dispatch
âœ… Fallbacks funcionam sem GPU
```

### Day 6 Checkpoint
```
âœ… Todos os testes unitÃ¡rios passam
âœ… Benchmarks mostram 3.6-12.5x ganho total
âœ… Sem regressÃµes vs versÃ£o anterior
âœ… Scaling confirms (14x em 16 cores vs 8x antes)
```

### Day 7 Checkpoint
```
âœ… DocumentaÃ§Ã£o completa
âœ… Commit pronto com messages descritivas
âœ… PR review-ready
âœ… Pronto para produÃ§Ã£o
```

---

## ðŸ”„ Build & Test Commands

### CompilaÃ§Ã£o

```bash
# Clean rebuild
make clean && ./configure --enable-cuda --enable-openmp && make

# Apenas tree reduction
make && php -d enable_dl=Off -r "
  \$a = new ZTensor([10000000]);
  \$a->fill(2.0);
  echo \"Testing sum tree reduction...\n\";
"

# Com debug symbols
./configure CFLAGS="-O2 -g" --enable-cuda && make
gdb php -x gdb_commands.txt
```

### Testes

```bash
# Unit tests
php tests/test_tree_reduction.php
php tests/test_kernel_fusion.php
php tests/test_auto_dispatch.php

# Benchmarks
php benchmarks/bench_tree_reduction.php
php benchmarks/bench_fusion.php
php benchmarks/bench_dispatch.php

# Full regression
php run-tests.php
```

### VerificaÃ§Ãµes

```bash
# Check GPU dispatch decision
ZMATRIX_GPU_DEBUG=1 php test_dispatch.php

# Profiling
perf record php benchmark.php
perf report

# Memory usage
valgrind --tool=massif php benchmark.php
```

---

## ðŸ“Š Success Criteria

| MÃ©trica | Target | Acceptance |
|---------|--------|-----------|
| Tree Reduction Speedup | 2.5-3.5x | â‰¥ 2.0x |
| Fusion Speedup | 2-3x | â‰¥ 1.5x |
| Auto-Dispatch Overhead | < 1% | < 2% |
| Combined Speedup | 3.6-12x | â‰¥ 3.0x |
| Test Pass Rate | 100% | 100% |
| Zero Regressions | Yes | Yes |
| GPU Fallback Safe | Yes | Yes |
| Documentation | Complete | > 90% |

---

## ðŸš€ Launch Plan

### Pre-Launch (Day 0)
- [ ] Feature branch criado
- [ ] Plano compartilhado com team
- [ ] Ambiente de teste preparado

### Development (Days 1-5)
- [ ] Daily standup confirma progresso
- [ ] WIP commits em feature branch
- [ ] Tests rodam a cada checkpoint

### Testing (Day 6)
- [ ] QA testa em mÃºltiplos hardware
- [ ] Benchmarks validados
- [ ] DocumentaÃ§Ã£o review

### Release (Day 7)
- [ ] PR criado com descriÃ§Ã£o detalhada
- [ ] Code review aprovado
- [ ] Merge para main branch
- [ ] Tag version criada
- [ ] Release notes publicadas

---

## ðŸ“ Template de Commit

```
commit: Implement tree reduction for parallel operations

WHAT:
- Add sum_f32_tree(), mean_f32_tree(), std_f32_tree() with block-based reduction
- Integrate into ZTensor::sum(), mean(), std() methods
- SIMD horizontal reduction within each block (AVX2)

WHY:
- Eliminate OpenMP synchronization overhead
- Cache-friendly block processing
- 2.5-3.5x speedup on large tensors (>40K elements)

HOW:
- Each thread processes independent block (256 elements)
- SIMD reduction within block (no sync)
- Final reduction of block results (sequencial)
- Tested: bit-exact vs simple reduction, scaling on 16 cores

PERFORMANCE:
- sum(100M): 45ms â†’ 15ms (3.0x)
- mean(100M): 50ms â†’ 18ms (2.8x)
- std(100M): 85ms â†’ 25ms (3.4x)

TESTS:
- Unit tests: test_tree_reduction.php âœ“
- Benchmark: bench_tree_reduction.php âœ“
- Regression: run-tests.php âœ“
```

---

## ðŸŽ“ Lessons Learned Framework

Ao terminar cada fase, documentar:

```markdown
## PHASE 1: Tree Reduction

### What Worked Well
- Bloco-based reduction muito eficiente
- SIMD dentro do bloco = ideal
- Scaling linear com threads (14x em 16 cores)

### What Was Challenging
- ReduÃ§Ã£o horizontal de __m256 requer permutaÃ§Ã£o
- Balancing block size vs overhead

### What Would You Do Differently
- Maybe start with 512-element blocks
- Profile different block sizes

### Key Insights
- Memory bandwidth Ã© o gargalo real
- Tree reduction elimina sync, nÃ£o speedup computation
```

---

## ðŸ“ž Escalation Path

If blocked or uncertain:

```
Tree Reduction Issue?
  â†’ Check: memory bandwidth saturation
  â†’ Check: block size optimization
  â†’ Check: SIMD horizontal reduction correctness

Fusion Issue?
  â†’ Check: numerical accuracy (1e-5 tolerance)
  â†’ Check: compiler optimizations (-O3 -march=native)
  â†’ Check: register pressure

Auto-Dispatch Issue?
  â†’ Check: threshold calibration on your hardware
  â†’ Check: ZMATRIX_GPU_DEBUG environment variable
  â†’ Check: fallback paths work
```

---

## âœ¨ Final Verification Checklist

Before declaring "done":

- [ ] CÃ³digo compila sem warnings
- [ ] Testes passam (100%)
- [ ] Benchmarks executam sem crashes
- [ ] DocumentaÃ§Ã£o Ã© clara e completa
- [ ] Exemplos em PHP funcionam
- [ ] GPU fallback funciona (export ZMATRIX_FORCE_CPU=1)
- [ ] Sem memory leaks (valgrind clean)
- [ ] Performance matches targets (Â±10%)
- [ ] Ready for production deployment

---

*Checklist de ImplementaÃ§Ã£o - 17 de Janeiro de 2026*  
**Status: PRONTO PARA COMEÃ‡AR** ðŸš€
